# =============================================================================
# RecSys V3 - Environment Variables Configuration
# =============================================================================
# Autor: Equipo ADX
# Descripción: Variables de entorno para configuración de AWS S3, MLflow y API
#
# Instrucciones:
# 1. Copiar este archivo como .env: cp .env.example .env
# 2. Completar con tus valores reales
# 3. Nunca commitear el archivo .env al repositorio
# =============================================================================

# -----------------------------------------------------------------------------
# AWS S3 Configuration
# -----------------------------------------------------------------------------
# Bucket principal donde se almacenarán datos y modelos
AWS_S3_BUCKET_NAME=recsys-v3-bucket

# Credenciales de AWS (dejar vacío si se usa IAM Role en EC2/ECS/Lambda)
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

# Región de AWS donde está el bucket
AWS_REGION=us-east-1

# -----------------------------------------------------------------------------
# S3 Data Paths (rutas dentro del bucket)
# -----------------------------------------------------------------------------
# Estructura recomendada:
# s3://recsys-v3-bucket/
# ├── data/
# │   ├── raw/                    # Datos originales
# │   ├── sampled/                # Datos muestreados
# │   ├── features/               # Features ingenieras
# │   └── validation/             # Reportes de validación
# ├── models/                     # Modelos entrenados
# │   └── YYYY-MM-DD/            # Organizados por fecha
# ├── reports/                    # Métricas y evaluaciones
# │   └── YYYY-MM-DD/
# └── mlflow/                     # Artifacts de MLflow

# Prefijos de rutas en S3 (sin el nombre del bucket)
S3_RAW_DATA_PATH=data/raw
S3_SAMPLED_DATA_PATH=data/sampled
S3_FEATURES_PATH=data/features
S3_MODELS_PATH=models
S3_REPORTS_PATH=reports
S3_VALIDATION_PATH=data/validation
S3_MLFLOW_ARTIFACTS_PATH=mlflow/artifacts

# Nombre del archivo de datos raw en S3
S3_RAW_DATA_FILENAME=df_extendida_clean.parquet

# -----------------------------------------------------------------------------
# Storage Mode Configuration
# -----------------------------------------------------------------------------
# Modo de almacenamiento: "local" o "s3"
# - local: usa carpetas locales (data/, models/, reports/)
# - s3: usa AWS S3 para almacenamiento
STORAGE_MODE=s3

# Si STORAGE_MODE=local, usar rutas locales por defecto
LOCAL_DATA_DIR=data
LOCAL_MODELS_DIR=models
LOCAL_REPORTS_DIR=reports

# -----------------------------------------------------------------------------
# MLflow Configuration
# -----------------------------------------------------------------------------
# URI del tracking server de MLflow
# Opciones:
# - Local: ./mlruns
# - Remote: http://mlflow-server:5000
# - S3: s3://recsys-v3-bucket/mlflow
MLFLOW_TRACKING_URI=./mlruns

# Nombre del experimento de MLflow
MLFLOW_EXPERIMENT_NAME=recsys_v3_training

# Backend store para MLflow (sqlite, postgresql, mysql)
MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db

# Artifact root para MLflow (puede ser S3)
MLFLOW_ARTIFACT_ROOT=s3://recsys-v3-bucket/mlflow/artifacts

# -----------------------------------------------------------------------------
# API Configuration (FastAPI)
# -----------------------------------------------------------------------------
# Host y puerto de la API
API_HOST=0.0.0.0
API_PORT=8001

# Ambiente de ejecución
ENVIRONMENT=production

# Nivel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# CORS origins permitidos (separados por coma)
CORS_ORIGINS=http://localhost:3000,http://localhost:8501,https://mi-app.com

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
# Nombre del modelo registrado en MLflow
MODEL_NAME=recsys_dnn

# Versión del modelo a usar en producción (latest, 1, 2, etc.)
MODEL_VERSION=latest

# Ruta del modelo en S3 (se sobrescribe si se usa MLflow)
MODEL_S3_PATH=models/dnn_model.pth

# Rutas de artifacts del modelo
LABEL_ENCODERS_S3_PATH=models/label_encoders.pkl
FEATURE_COLUMNS_S3_PATH=models/feature_columns.pkl
LOCATION_FILTER_S3_PATH=models/location_filter.pkl

# -----------------------------------------------------------------------------
# Pipeline Configuration
# -----------------------------------------------------------------------------
# Tamaño de muestra para desarrollo (0 = usar todos los datos)
SAMPLE_SIZE=2000

# Seed para reproducibilidad
RANDOM_STATE=42

# Usar carpetas con fecha para outputs (true/false)
USE_DATE_FOLDERS=true

# Formato de fecha para carpetas (Python strftime format)
DATE_FOLDER_FORMAT=%Y-%m-%d

# Incluir timestamp en nombres de archivo (true/false)
USE_TIMESTAMP=false

# -----------------------------------------------------------------------------
# Training Configuration
# -----------------------------------------------------------------------------
# Número de epochs
EPOCHS=50

# Batch size
BATCH_SIZE=32

# Learning rate
LEARNING_RATE=0.0001967641848109

# Early stopping patience
EARLY_STOPPING_PATIENCE=10

# Device (cpu, cuda, mps)
DEVICE=cpu

# -----------------------------------------------------------------------------
# Azure DevOps Configuration
# -----------------------------------------------------------------------------
# URL de la organización de Azure DevOps
AZURE_DEVOPS_ORG_URL=https://dev.azure.com/tu-organizacion

# Nombre del proyecto
AZURE_DEVOPS_PROJECT=RecSys-V3

# Personal Access Token (PAT) para Azure DevOps
AZURE_DEVOPS_PAT=tu_personal_access_token_aqui

# Service Connection name para AWS en Azure DevOps
AZURE_AWS_SERVICE_CONNECTION=aws-recsys-connection

# -----------------------------------------------------------------------------
# Monitoring & Alerting
# -----------------------------------------------------------------------------
# Habilitar monitoreo de drift
ENABLE_DRIFT_DETECTION=true

# Threshold para alertas de drift
DRIFT_THRESHOLD=0.1

# Email para notificaciones (separados por coma)
ALERT_EMAILS=equipo-adx@ejemplo.com,ops@ejemplo.com

# -----------------------------------------------------------------------------
# Security & Secrets
# -----------------------------------------------------------------------------
# Secret key para la API (generar con: openssl rand -hex 32)
API_SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32

# Token de autenticación para endpoints protegidos
API_AUTH_TOKEN=your-api-auth-token-here

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------
# Habilitar caché de modelos
ENABLE_MODEL_CACHE=true

# Habilitar logging detallado
ENABLE_DETAILED_LOGGING=false

# Habilitar validación de datos con Evidently
ENABLE_DATA_VALIDATION=true

# Habilitar registro automático en MLflow
ENABLE_MLFLOW_AUTOLOG=true

# -----------------------------------------------------------------------------
# Database Configuration (Opcional - para features futuras)
# -----------------------------------------------------------------------------
# PostgreSQL connection string
# DATABASE_URL=postgresql://user:password@localhost:5432/recsys_v3

# Redis para caché (opcional)
# REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# Notas Importantes
# -----------------------------------------------------------------------------
# 1. Para producción en AWS, considera usar AWS Secrets Manager en lugar de .env
# 2. Para Azure, considera usar Azure Key Vault
# 3. Si usas ECS/EC2, puedes usar IAM Roles en lugar de AWS credentials
# 4. Asegúrate de que .env está en .gitignore
# 5. Para CI/CD, configura estas variables como secrets en tu plataforma
